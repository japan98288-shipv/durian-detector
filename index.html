<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Intelligent Leaf Scan AI (Speed Optimized)</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
    
    <style>
        body { font-family: sans-serif; }
        .video-container {
            position: relative;
            display: inline-block;
            overflow: hidden; 
            width: 100%; 
        }
        #videoElement {
            width: 100%; 
            height: auto;
            display: block;
        }
        #canvasOverlay {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 10;
            pointer-events: none; 
        }
    </style>
</head>
<body class="bg-light">
    <nav class="navbar navbar-expand-lg navbar-dark bg-success fixed-top shadow-lg">
        <div class="container-fluid">
            <a class="navbar-brand fw-bold" href="#">Intelligent LeafScanner (Speed Optimized)</a>
            <button class="btn btn-sm btn-outline-light" type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvasMenu" aria-controls="offcanvasMenu">
                <i class="bi bi-list fs-4"></i>
            </button>
        </div>
    </nav>
    
    <div style="height: 60px;"></div> 

    <div class="container mt-4">
        <div id="camera_section">
            <h1 class="text-center mb-4 text-success fw-bold">‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏û‡∏∑‡∏ä‡πÅ‡∏ö‡∏ö Real-Time</h1>
            
            <div class="card shadow-lg mx-auto" style="max-width: 640px;">
                <div class="card-body p-0"> 
                    <div class="video-container" id="video-wrapper">
                        <video id="videoElement" autoplay playsinline></video>
                        <canvas id="canvasOverlay"></canvas>
                    </div>
                </div>
                
                <div class="card-footer text-center p-3 bg-white">
                    <button id="startButton" class="btn btn-primary btn-lg w-100 shadow-sm">
                        <i class="bi bi-camera-video"></i> ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
                    </button>
                    <p id="status" class="mt-3 fs-6 fw-bold text-info">‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°...</p>
                    <p id="connectionStatus" class="mt-2 fs-6 fw-bold text-danger">‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ API: ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö...</p> 
                    <p id="detectionCount" class="text-muted small">‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö: 0</p>
                </div>
            </div>
        </div>
        
        <div id="results_history" class="container mt-5 p-4 border rounded bg-white shadow-sm">
            <h2 class="text-primary"><i class="bi bi-list-columns"></i> ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå</h2>
            <p class="text-muted">‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ (‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°)</p>
        </div>
    </div> 
    
    <div class="offcanvas offcanvas-start bg-light" tabindex="-1" id="offcanvasMenu" aria-labelledby="offcanvasMenuLabel">
        <div class="offcanvas-header bg-success text-white">
            <h5 class="offcanvas-title" id="offcanvasMenuLabel">‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏ô‡∏π</h5>
            <button type="button" class="btn-close text-reset" data-bs-dismiss="offcanvas" aria-label="Close"></button>
        </div>
        <div class="offcanvas-body">
            <ul class="navbar-nav justify-content-end flex-grow-1 pe-3">
                <li class="nav-item mb-2">
                    <a class="nav-link active fs-5 text-success" href="#camera_section" data-bs-dismiss="offcanvas">
                        <i class="bi bi-camera-video"></i> ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö (‡∏Å‡∏•‡πâ‡∏≠‡∏á)
                    </a>
                </li>
                <li class="nav-item"><a class="nav-link fs-5" href="#" target="_blank" data-bs-dismiss="offcanvas"><i class="bi bi-tree-fill"></i> ‡πÉ‡∏ö‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô</a></li>
                <li class="nav-item"><a class="nav-link fs-5" href="#" target="_blank" data-bs-dismiss="offcanvas"><i class="bi bi-tree-fill"></i> ‡πÉ‡∏ö‡∏°‡∏±‡∏á‡∏Ñ‡∏∏‡∏î</a></li>
                <li class="nav-item"><a class="nav-link fs-5" href="#" target="_blank" data-bs-dismiss="offcanvas"><i class="bi bi-tree-fill"></i> ‡πÉ‡∏ö‡πÄ‡∏á‡∏≤‡∏∞</a></li>
                <li class="nav-item"><a class="nav-link fs-5" href="#" target="_blank" data-bs-dismiss="offcanvas"><i class="bi bi-tree-fill"></i> ‡πÉ‡∏ö‡∏•‡∏≠‡∏á‡∏Å‡∏≠‡∏á</a></li>
            </ul>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>

    <script>
    
    // *** ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API ***
    const BASE_API_URL = "https://tawanna-ionogenic-gyrally.ngrok-free.dev"; 
    const API_URL = `${BASE_API_URL}/detect_disease`; 
    
    const AI_INPUT_SIZE = 480; // üéØ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô 480x480
    
    // Element References
    const video = document.getElementById('videoElement');
    const canvas = document.getElementById('canvasOverlay');
    const videoWrapper = document.getElementById('video-wrapper');
    const startButton = document.getElementById('startButton');
    const statusElement = document.getElementById('status');
    const detectionCountElement = document.getElementById('detectionCount');
    const connectionStatusElement = document.getElementById('connectionStatus');
    const ctx = canvas.getContext('2d');
    
    // Global State Variables
    let stream = null;
    let isProcessing = false;
    let isBackendConnected = false;
    
    let latestDetectionData = { 
        boxes: [], 
        detections: 0 
    }; 

    let frameSendInterval = 350; // ‚ö° ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏î‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏†‡∏≤‡∏û (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡∏Å‡∏ß‡πà‡∏≤ 550ms)
    let lastSendTime = 0; 

    // ----------------------------------------------------------------------
    // ** 1. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å: Loop ‡∏Å‡∏≤‡∏£ Render 60 FPS **
    // ----------------------------------------------------------------------
    function drawLoop() {
        if (!isProcessing) return; 
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        drawBoundingBoxes(latestDetectionData.boxes); 

        const now = performance.now();
        if (now - lastSendTime >= frameSendInterval) {
            sendFrame(now); 
            lastSendTime = now;
        }

        requestAnimationFrame(drawLoop);
    }

    // ----------------------------------------------------------------------
    // ** 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏≤‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á Bounding Boxes **
    // ----------------------------------------------------------------------
    function drawBoundingBoxes(boxes) {
        if (!boxes || boxes.length === 0) return;

        const scaleX = canvas.width / AI_INPUT_SIZE;
        const scaleY = canvas.height / AI_INPUT_SIZE;
        
        const videoStyle = window.getComputedStyle(video);
        const isMirrored = videoStyle.getPropertyValue('transform').includes('scaleX(-1)');

        ctx.lineWidth = 3; 
        ctx.font = 'bold 16px Arial'; 
        ctx.textAlign = 'start';
        ctx.strokeStyle = '#dc3545';
        ctx.fillStyle = '#dc3545'; 

        boxes.forEach(detection => {
            const [x1_ai, y1_ai, x2_ai, y2_ai] = detection.box; 
            const conf = detection.confidence;
            const name = detection.class;
            
            let x1 = x1_ai * scaleX;
            const y1 = y1_ai * scaleY;
            const width = (x2_ai - x1_ai) * scaleX;
            const height = (y2_ai - y1_ai) * scaleY;

            if (isMirrored) {
                x1 = canvas.width - (x1 + width);
            }
            
            ctx.strokeRect(x1, y1, width, height); 
            
            const label = `${name} (${(conf * 100).toFixed(0)}%)`; 
            
            const textWidth = ctx.measureText(label).width;
            ctx.fillRect(x1 - 1, y1 - 20, textWidth + 8, 20);
            
            ctx.fillStyle = 'white';
            ctx.fillText(label, x1 + 3, y1 - 5);
            ctx.fillStyle = '#dc3545'; 
        });
    }

    // ----------------------------------------------------------------------
    // ** 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° **
    // ----------------------------------------------------------------------
    
    async function checkBackendConnectivity() {
        try {
            connectionStatusElement.textContent = "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ API: ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö...";
            connectionStatusElement.classList.remove('text-success', 'text-danger');
            connectionStatusElement.classList.add('text-warning');

            const response = await fetch(BASE_API_URL, { method: 'GET' });

            if (response.ok || response.status === 404 || response.status === 405) {
                isBackendConnected = true;
                connectionStatusElement.textContent = "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ API: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå)";
                connectionStatusElement.classList.remove('text-warning', 'text-danger');
                connectionStatusElement.classList.add('text-success');
                return true;
            } else {
                throw new Error(`Server responded with status: ${response.status}`);
            }

        } catch (error) {
            isBackendConnected = false;
            connectionStatusElement.textContent = `‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ API: ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß! (${error.message})`;
            connectionStatusElement.classList.remove('text-warning', 'text-success');
            connectionStatusElement.classList.add('text-danger');
            statusElement.textContent = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Backend ‡πÑ‡∏î‡πâ";
            console.error("Backend Connection Check Failed:", error);
            return false;
        }
    }
    
    async function initializeCamera(constraints) {
        try {
            const currentStream = await navigator.mediaDevices.getUserMedia(constraints);
            return currentStream;
        } catch (err) {
            console.warn(`Camera init failed with constraint: ${JSON.stringify(constraints)}`, err.name);
            return null;
        }
    }
    
    function setupVideoAndStartLoop(currentStream) {
        return new Promise((resolve) => {
            stream = currentStream;
            video.srcObject = stream;

            video.load(); 

            video.onloadedmetadata = () => {
                video.play();
                
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                
                setTimeout(() => {
                    const videoRect = video.getBoundingClientRect();
                    canvas.style.width = `${videoRect.width}px`;
                    canvas.style.height = `${videoRect.height}px`;
                    videoWrapper.style.height = `${videoRect.height}px`; 
                    console.log(`Camera Stream Ready: ${canvas.width}x${canvas.height} | CSS: ${videoRect.width}px x ${videoRect.height}px`);
                }, 100); 

                statusElement.textContent = "‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö...";
                startButton.textContent = "‡∏´‡∏¢‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö";
                startButton.classList.remove('btn-primary');
                startButton.classList.add('btn-danger');

                isProcessing = true;
                drawLoop(); 
                
                startButton.onclick = stopDetection;
                resolve();
            };
        });
    }

    async function startCamera() {
        if (!isBackendConnected) {
            statusElement.textContent = "‡∏´‡∏¢‡∏∏‡∏î! Backend ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô";
            return false;
        }

        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            statusElement.textContent = "‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö MediaDevices API";
            return false;
        }

        statusElement.textContent = "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á (‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô)...";

        const constraintList = [
            { video: true },                               
            { video: { facingMode: 'user' } },              
            { video: { facingMode: 'environment' } },      
        ];
        
        let successfulStream = null;
        for (const constraints of constraintList) {
            successfulStream = await initializeCamera(constraints);
            if (successfulStream) {
                break; 
            }
        }

        if (successfulStream) {
            await setupVideoAndStartLoop(successfulStream);
            return true;
        } else {
            statusElement.textContent = `‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå)`;
            startButton.textContent = "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö (‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)";
            return false;
        }
    }

    function stopDetection() {
        if (stream) {
            stream.getTracks().forEach(track => track.stop());
            video.srcObject = null;
        }
        isProcessing = false;
        statusElement.textContent = "‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß";
        startButton.textContent = "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö";
        startButton.classList.remove('btn-danger');
        startButton.classList.add('btn-primary');
        startButton.onclick = startDetectionProcess; 
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        latestDetectionData = { boxes: [], detections: 0 }; 
    }

    async function sendFrame(sendTime) {
        if (!isProcessing || video.paused || video.ended) {
            return;
        }

        try {
            const captureCanvas = document.createElement('canvas');
            const captureCtx = captureCanvas.getContext('2d');
            const CAPTURE_SIZE = AI_INPUT_SIZE; // 480
            captureCanvas.width = CAPTURE_SIZE;
            captureCanvas.height = CAPTURE_SIZE;

            captureCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight, 0, 0, CAPTURE_SIZE, CAPTURE_SIZE);

            captureCanvas.toBlob(async (blob) => {
                if (!blob) return;

                const formData = new FormData();
                formData.append('file', blob, 'frame.jpg');

                statusElement.textContent = "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...";
                
                const response = await fetch(API_URL, {
                    method: 'POST',
                    body: formData,
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    statusElement.textContent = `‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î API: ‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ ${response.status} (Backend/ngrok ‡∏≠‡∏≤‡∏à‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà)`;
                    connectionStatusElement.textContent = `‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ API: ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß! (${response.status})`;
                    console.error("HTTP Error from Backend:", response.status, errorText.substring(0, 100) + '...');
                    stopDetection();
                    return; 
                }

                let result;
                try {
                    result = await response.json();
                } catch (e) {
                    statusElement.textContent = `‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î API: ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà JSON (ngrok/Cloudflare Error?)`;
                    connectionStatusElement.textContent = `‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ API: ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•`;
                    console.error("JSON Parsing Error:", e);
                    stopDetection();
                    return; 
                }

                // 3. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                let boxesData;
                let detectionCount;
                
                if (result.status === 'success') { 
                    const detectionsArray = result.detections;
                    
                    if (detectionsArray && Array.isArray(detectionsArray)) {
                        boxesData = detectionsArray.map(d => ({
                            box: [d.box[0], d.box[1], d.box[2], d.box[3]], 
                            confidence: d.confidence,
                            class: d.class
                        }));
                        detectionCount = result.detections_count || boxesData.length;
                    } else {
                        console.warn("API returned status 'success' but detections data is missing or not an Array.", result);
                        boxesData = [];
                        detectionCount = 0;
                    }
                } else {
                    console.warn("API response received but status is not 'success'.", result);
                    boxesData = [];
                    detectionCount = 0;
                }

                latestDetectionData = {
                    boxes: boxesData,
                    detections: detectionCount
                };
                
                detectionCountElement.textContent = `‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö: ${detectionCount} ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏`;
                const processingTime = performance.now() - sendTime;
                statusElement.textContent = `‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! (Lat: ${processingTime.toFixed(0)}ms) - ${Math.round(1000/frameSendInterval)} FPS`;

            }, 'image/jpeg', 0.4); // üñºÔ∏è ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô 0.4

        } catch (error) {
            statusElement.textContent = `‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÑ‡∏î‡πâ`;
            connectionStatusElement.textContent = `‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ API: ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£`;
            console.error("Detection API Network Error:", error);
            
            isProcessing = false; 
            stopDetection();
        }
    }
    
    async function startDetectionProcess() {
        const isReady = await checkBackendConnectivity(); 
        if (isReady) {
            isProcessing = true;
            startCamera(); 
        } else {
            isProcessing = false;
        }
    };

    startButton.onclick = startDetectionProcess;

    window.onload = async function() {
        statusElement.textContent = "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö";
        await checkBackendConnectivity(); 
    };

    window.addEventListener('beforeunload', () => {
        stopDetection();
        if (stream) {
            stream.getTracks().forEach(track => track.stop());
        }
    });

    </script>
</body>
</html>